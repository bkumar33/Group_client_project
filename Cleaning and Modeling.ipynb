{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10008, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Informativeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I've got enough candles to supply a Mexican family</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, NY) http://t.co/VSiZrzKP</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "1  1            \n",
       "2  2            \n",
       "3  3            \n",
       "4  4            \n",
       "\n",
       "                                                                                                    Tweet Text  \\\n",
       "0  I've got enough candles to supply a Mexican family                                                            \n",
       "1  Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy                                 \n",
       "2  @ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.   \n",
       "3  @taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?                \n",
       "4  I'm at Mad River Bar &amp; Grille (New York, NY) http://t.co/VSiZrzKP                                         \n",
       "\n",
       "  Informativeness  \n",
       "0  off-topic       \n",
       "1  on-topic        \n",
       "2  off-topic       \n",
       "3  off-topic       \n",
       "4  off-topic       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('final_data_sets/cleaned_tweet_train_data.csv')\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Text</th>\n",
       "      <th>Informativeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've got enough candles to supply a Mexican family</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, NY) http://t.co/VSiZrzKP</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    Tweet Text  \\\n",
       "0  I've got enough candles to supply a Mexican family                                                            \n",
       "1  Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy                                 \n",
       "2  @ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.   \n",
       "3  @taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?                \n",
       "4  I'm at Mad River Bar &amp; Grille (New York, NY) http://t.co/VSiZrzKP                                         \n",
       "\n",
       "  Informativeness  \n",
       "0  off-topic       \n",
       "1  on-topic        \n",
       "2  off-topic       \n",
       "3  off-topic       \n",
       "4  off-topic       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = ['tweet_text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've got enough candles to supply a Mexican family</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, NY) http://t.co/VSiZrzKP</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    tweet_text  \\\n",
       "0  I've got enough candles to supply a Mexican family                                                            \n",
       "1  Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy                                 \n",
       "2  @ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.   \n",
       "3  @taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?                \n",
       "4  I'm at Mad River Bar &amp; Grille (New York, NY) http://t.co/VSiZrzKP                                         \n",
       "\n",
       "       label  \n",
       "0  off-topic  \n",
       "1  on-topic   \n",
       "2  off-topic  \n",
       "3  off-topic  \n",
       "4  off-topic  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tweet_text'] = dataset['tweet_text'].str.replace('[^\\w\\s]','')\n",
    "dataset['tweet_text'] = dataset['tweet_text'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "dataset['tweet_text'] = dataset['tweet_text'].str.replace('\\\\n', ' ', case=False)\n",
    "dataset['tweet_text'] = dataset['tweet_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive got enough candles to supply a mexican family</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandy be soooo mad that she be shattering our doors and shiet hurricanesandy</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ibexgirl thankfully hurricane waugh played it cool and waited this one out ready to go at any moment tho</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taos you never got that magnificent case of burgundy i sent you to thank you for your tweets</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im at mad river bar amp grille new york ny</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 tweet_text  \\\n",
       "0  ive got enough candles to supply a mexican family                                                          \n",
       "1  sandy be soooo mad that she be shattering our doors and shiet hurricanesandy                               \n",
       "2  ibexgirl thankfully hurricane waugh played it cool and waited this one out ready to go at any moment tho   \n",
       "3  taos you never got that magnificent case of burgundy i sent you to thank you for your tweets               \n",
       "4  im at mad river bar amp grille new york ny                                                                 \n",
       "\n",
       "       label  \n",
       "0  off-topic  \n",
       "1  on-topic   \n",
       "2  off-topic  \n",
       "3  off-topic  \n",
       "4  off-topic  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>sandy is a weak name for a hurricane</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>seaoftime so freaking excited d and i dont knowi have no plans because of the hurricane</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>rt czd123 i dont find these hurricane jokes funny itsnotajoke</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>best wishes to our friends in the northeast stay safe hurricane sandy</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>update 7threat of hurricane sandy grows as it targets us east coast  reuters economic timesupdate 7threat of</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                          tweet_text  \\\n",
       "10003  sandy is a weak name for a hurricane                                                                            \n",
       "10004  seaoftime so freaking excited d and i dont knowi have no plans because of the hurricane                         \n",
       "10005  rt czd123 i dont find these hurricane jokes funny itsnotajoke                                                   \n",
       "10006  best wishes to our friends in the northeast stay safe hurricane sandy                                           \n",
       "10007  update 7threat of hurricane sandy grows as it targets us east coast  reuters economic timesupdate 7threat of    \n",
       "\n",
       "          label  \n",
       "10003  on-topic  \n",
       "10004  on-topic  \n",
       "10005  on-topic  \n",
       "10006  on-topic  \n",
       "10007  on-topic  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "on-topic     6138\n",
       "off-topic    3870\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing label to numeric for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'on-topic':1, \n",
    "         'off-topic':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['label'] = dataset['label'].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive got enough candles to supply a mexican family</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandy be soooo mad that she be shattering our doors and shiet hurricanesandy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ibexgirl thankfully hurricane waugh played it cool and waited this one out ready to go at any moment tho</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taos you never got that magnificent case of burgundy i sent you to thank you for your tweets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im at mad river bar amp grille new york ny</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 tweet_text  \\\n",
       "0  ive got enough candles to supply a mexican family                                                          \n",
       "1  sandy be soooo mad that she be shattering our doors and shiet hurricanesandy                               \n",
       "2  ibexgirl thankfully hurricane waugh played it cool and waited this one out ready to go at any moment tho   \n",
       "3  taos you never got that magnificent case of burgundy i sent you to thank you for your tweets               \n",
       "4  im at mad river bar amp grille new york ny                                                                 \n",
       "\n",
       "   label  \n",
       "0  0      \n",
       "1  1      \n",
       "2  0      \n",
       "3  0      \n",
       "4  0      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6138\n",
       "0    3870\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming the tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tweets):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stemmer = PorterStemmer()\n",
    "    tweet_token = tokenizer.tokenize(tweets)\n",
    "    return ' '.join(map(lambda x: stemmer.stem(x), tweet_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['stemmed_tweet'] = dataset['tweet_text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>label</th>\n",
       "      <th>stemmed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive got enough candles to supply a mexican family</td>\n",
       "      <td>0</td>\n",
       "      <td>ive got enough candl to suppli a mexican famili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sandy be soooo mad that she be shattering our doors and shiet hurricanesandy</td>\n",
       "      <td>1</td>\n",
       "      <td>sandi be soooo mad that she be shatter our door and shiet hurricanesandi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ibexgirl thankfully hurricane waugh played it cool and waited this one out ready to go at any moment tho</td>\n",
       "      <td>0</td>\n",
       "      <td>ibexgirl thank hurrican waugh play it cool and wait thi one out readi to go at ani moment tho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taos you never got that magnificent case of burgundy i sent you to thank you for your tweets</td>\n",
       "      <td>0</td>\n",
       "      <td>tao you never got that magnific case of burgundi i sent you to thank you for your tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im at mad river bar amp grille new york ny</td>\n",
       "      <td>0</td>\n",
       "      <td>im at mad river bar amp grill new york ny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 tweet_text  \\\n",
       "0  ive got enough candles to supply a mexican family                                                          \n",
       "1  sandy be soooo mad that she be shattering our doors and shiet hurricanesandy                               \n",
       "2  ibexgirl thankfully hurricane waugh played it cool and waited this one out ready to go at any moment tho   \n",
       "3  taos you never got that magnificent case of burgundy i sent you to thank you for your tweets               \n",
       "4  im at mad river bar amp grille new york ny                                                                 \n",
       "\n",
       "   label  \\\n",
       "0  0       \n",
       "1  1       \n",
       "2  0       \n",
       "3  0       \n",
       "4  0       \n",
       "\n",
       "                                                                                   stemmed_tweet  \n",
       "0  ive got enough candl to suppli a mexican famili                                                \n",
       "1  sandi be soooo mad that she be shatter our door and shiet hurricanesandi                       \n",
       "2  ibexgirl thank hurrican waugh play it cool and wait thi one out readi to go at ani moment tho  \n",
       "3  tao you never got that magnific case of burgundi i sent you to thank you for your tweet        \n",
       "4  im at mad river bar amp grill new york ny                                                      "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested models with stemmed tweet and without, our model produced better results without using stemming function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "#### 1. Logistic Regression \n",
    "#### 2. SVM\n",
    "#### 3. Random forest \n",
    "#### 4. Mutlinomal Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['tweet_text']\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.613309\n",
       "0    0.386691\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know our baseline score is about 61.33 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with countvectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=2)]: Done  90 out of  90 | elapsed:   16.5s finished\n",
      "/Users/bhupeshkumar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'cvec__min_df': 6, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english'}\n",
      "Train Score:  0.9511057820410338\n",
      "Test Score:  0.9276578737010391\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_cvec = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cvec__min_df':[2, 4, 6],                   \n",
    "    'cvec__ngram_range':[(1,1),(1,2),(1,3)],\n",
    "    'cvec__stop_words':[None, 'english'],\n",
    "}\n",
    "\n",
    "gs_lr_cvec = GridSearchCV(pipe_lr_cvec, \n",
    "                          params, \n",
    "                          cv=5,\n",
    "                          n_jobs=2,\n",
    "                          verbose=1)\n",
    "                         \n",
    "\n",
    "gs_lr_cvec.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs_lr_cvec.best_params_)\n",
    "print('Train Score: ', gs_lr_cvec.best_estimator_.score(X_train, y_train))\n",
    "print('Test Score: ', gs_lr_cvec.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=2)]: Done 720 out of 720 | elapsed:  1.4min finished\n",
      "/Users/bhupeshkumar/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'lr__C': 1, 'lr__penalty': 'l1', 'lr__random_state': 42, 'tf__max_features': 500, 'tf__min_df': 1, 'tf__ngram_range': (1, 1), 'tf__stop_words': None}\n",
      "Train Score: 0.929656274980016\n",
      "Test Score: 0.9220623501199041\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_tf = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "params_lr_tf = {\n",
    "    'tf__stop_words':   [None, 'english'],\n",
    "    'tf__max_features': [500, 1000, 2000], \n",
    "    'tf__ngram_range':  [(1, 1), (1, 2)], \n",
    "    'tf__min_df' :      [1,2],\n",
    "    'lr__penalty':      ['l2', 'l1'],\n",
    "    'lr__C':            [.5, .01, 1],\n",
    "    'lr__random_state': [42] \n",
    "}\n",
    "gs_lr_tf = GridSearchCV(pipe_lr_tf, \n",
    "                        param_grid=params_lr_tf,\n",
    "                        cv=5,\n",
    "                        n_jobs=2,\n",
    "                        verbose=1)\n",
    "\n",
    "gs_lr_tf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best Params:', gs_lr_tf.best_params_)\n",
    "print('Train Score:', gs_lr_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_lr_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Logistic Regression with CountVectorize : \n",
    "    Train score is 95.11 %\n",
    "    Test score is 92.76 %\n",
    "        \n",
    "    Logistic Regression with TfidVectorizer : \n",
    "    Train score is 92.96 %\n",
    "    Test score is 92.20 %\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model With CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   41.6s finished\n",
      "/Users/bhupeshkumar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'cvec__min_df': 2, 'cvec__stop_words': 'english'}\n",
      "Train Score:  0.8960831334932055\n",
      "Test Score:  0.8968824940047961\n"
     ]
    }
   ],
   "source": [
    "pipe_svm_cvec = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cvec__min_df':[2,4,6],\n",
    "    'cvec__stop_words':[None ,'english'],\n",
    "}\n",
    "\n",
    "gs_svm_cvec = GridSearchCV(pipe_svm_cvec,\n",
    "                  params,\n",
    "                  cv=5, \n",
    "                  verbose=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_svm_cvec.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs_svm_cvec.best_params_)\n",
    "print('Train Score: ', gs_svm_cvec.best_estimator_.score(X_train, y_train))\n",
    "print('Test Score: ', gs_svm_cvec.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model with TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done  90 out of  90 | elapsed:  2.6min finished\n",
      "/Users/bhupeshkumar/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'tf__max_features': 500, 'tf__ngram_range': (1, 1), 'tf__stop_words': None}\n",
      "Train Score: 0.6133759658939515\n",
      "Test Score: 0.6131095123900879\n"
     ]
    }
   ],
   "source": [
    "pipe_svm_tf = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])\n",
    "\n",
    "params_svm_tf = {\n",
    "    'tf__stop_words':   [None, 'english'],\n",
    "    'tf__max_features': [500, 1000, 2000,], \n",
    "    'tf__ngram_range':  [(1, 1), (1, 2), (1, 3)], \n",
    "}\n",
    "gs_svm_tf = GridSearchCV(pipe_svm_tf, \n",
    "                        param_grid=params_svm_tf,\n",
    "                        cv=5,\n",
    "                        n_jobs=2,\n",
    "                        verbose=1)\n",
    "\n",
    "gs_svm_tf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best Params: ', gs_svm_tf.best_params_)\n",
    "print('Train Score:', gs_svm_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_svm_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    SVM with CountVectorize : \n",
    "    Train score is 89.60 %\n",
    "    Test score is 89.68 %\n",
    "\n",
    "    SVM with TfidVectorizer : \n",
    "    Train score is 61.33 %\n",
    "    Test score is 61.31 %\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest With Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'rf__max_depth': 75, 'rf__min_samples_split': 4, 'rf__n_estimators': 75}\n",
      "Train Score: 0.9634958699706901\n",
      "Test Score: 0.9212629896083133\n"
     ]
    }
   ],
   "source": [
    "pipe_rf_cvec = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier() )\n",
    "])\n",
    "\n",
    "params_rf_cvec = {\n",
    "    'cvec__min_df':[2,4],\n",
    "    'cvec__stop_words':[None ,'english'],\n",
    "    'cvec__ngram_range':[(1,2),(1,3)],\n",
    "    'rf__n_estimators':[75, 200],\n",
    "    'rf__max_depth':[25, 75],\n",
    "    'rf__min_samples_split':[2,4]\n",
    "}\n",
    "\n",
    "gs_rf_cvec = GridSearchCV(pipe_rf_cvec,\n",
    "                          params_rf_cvec,\n",
    "                          cv=5,\n",
    "                          verbose=2,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "gs_rf_cvec.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best Params:' , gs_rf_cvec.best_params_)\n",
    "print('Train Score:', gs_rf_cvec.score(X_train, y_train))\n",
    "print('Test Score:', gs_rf_cvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Tfidvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=2)]: Done  90 out of  90 | elapsed:   22.1s finished\n",
      "/Users/bhupeshkumar/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'tf__max_features': 2000, 'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "Train Score: 0.991207034372502\n",
      "Test Score: 0.9172661870503597\n"
     ]
    }
   ],
   "source": [
    "pipe_rf_tf = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params_rf_tf = {\n",
    "    'tf__stop_words':   [None, 'english'],\n",
    "    'tf__max_features': [500, 1000, 2000,], \n",
    "    'tf__ngram_range':  [(1, 1), (1, 2), (1, 3)], \n",
    "}\n",
    "gs_rf_tf = GridSearchCV(pipe_rf_tf, \n",
    "                        param_grid=params_svm_tf,\n",
    "                        cv=5,\n",
    "                        n_jobs=2,\n",
    "                        verbose=1)\n",
    "\n",
    "gs_rf_tf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best Params:', gs_rf_tf.best_params_)\n",
    "print('Train Score:', gs_rf_tf.score(X_train, y_train))\n",
    "print('Test Score:', gs_rf_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random Forest with CountVectorize : \n",
    "    Train score is 96.34 %\n",
    "    Test score is 92.12 %\n",
    "\n",
    "    Random Forest with TfidVectorizer : \n",
    "    Train score is 99.12 %\n",
    "    Test score is 91.72 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutlinomal Naive Bayes Model with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'cvec__min_df': 4, 'cvec__stop_words': None, 'nb__alpha': 2}\n",
      "Score Train:  0.8990141220357047\n",
      "Score Test:  0.8705035971223022\n"
     ]
    }
   ],
   "source": [
    "pipe_nb_cvec = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cvec__min_df':[1,2,4],\n",
    "    'cvec__stop_words':[None, 'english'],\n",
    "    'nb__alpha': [0.1,1,2]\n",
    "}\n",
    "\n",
    "gs_nb_cvec = GridSearchCV(pipe_nb_cvec, \n",
    "                  params, \n",
    "                  cv=5,\n",
    "                  verbose=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_nb_cvec.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ', gs_nb_cvec.best_params_)\n",
    "print('Score Train: ', gs_nb_cvec.score(X_train, y_train))\n",
    "print('Score Test: ', gs_nb_cvec.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutlinomal Naive Bayes Model with Tfidvectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'nb__alpha': 0.1, 'tf__max_features': 2000, 'tf__ngram_range': (1, 2), 'tf__stop_words': None}\n",
      "Score Train:  0.8878230748734346\n",
      "Score Test:  0.8481215027977618\n"
     ]
    }
   ],
   "source": [
    "pipe_nb_tf = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tf__stop_words':   [None, 'english'],\n",
    "    'tf__max_features': [1000, 2000],\n",
    "    'tf__ngram_range':  [(1,1), (1, 2)],\n",
    "    'nb__alpha': [0.1,1]\n",
    "}\n",
    "\n",
    "gs_nb_tf = GridSearchCV(pipe_nb_tf, \n",
    "                  params, \n",
    "                  cv=5,\n",
    "                  verbose=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_nb_tf.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params:' , gs_nb_tf.best_params_)\n",
    "print('Score Train: ', gs_nb_tf.score(X_train, y_train))\n",
    "print('Score Test: ', gs_nb_tf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Naive Bayes with CountVectorize : \n",
    "    Train score is 89.90 %\n",
    "    Test score is 87.05 %\n",
    "\n",
    "    Naive bayes with TfidVectorizer : \n",
    "    Train score is 88.78 %\n",
    "    Test score is 84.88 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the model, Logistic regression with Tfidvectorizer has the best score. We will make predictions using that model. \n",
    "\n",
    "    Logistic Regression with TfidVectorizer : \n",
    "    Train score is 92.96 %\n",
    "    Test score is 92.20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('final_data_sets/cleaned_tweet_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>place_name</th>\n",
       "      <th>coordinates_longitude</th>\n",
       "      <th>coordinates_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>I suppose she has an appropriate costume for every activity... #ilovemaggiesmith #downtonseasonthree</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>West Long Branch, NJ</td>\n",
       "      <td>-74.037008</td>\n",
       "      <td>40.272289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>@NOT_savinHOES Not r yu upp</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Bressler-Enhaut-Oberlin, PA</td>\n",
       "      <td>-76.831479</td>\n",
       "      <td>40.22417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>Hit and Run is so sad..</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>South Carolina, USA</td>\n",
       "      <td>-83.353955</td>\n",
       "      <td>32.04683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>Who's up?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Malden, MA</td>\n",
       "      <td>-71.089522</td>\n",
       "      <td>42.412466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>@augustushazel idk I'm just ugly or annoying or something</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Erie, PA</td>\n",
       "      <td>-80.239991</td>\n",
       "      <td>42.018414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      created_at  \\\n",
       "0  0           Mon Oct 22 05:00:00 +0000 2012   \n",
       "1  1           Mon Oct 22 05:00:00 +0000 2012   \n",
       "2  2           Mon Oct 22 05:00:00 +0000 2012   \n",
       "3  3           Mon Oct 22 05:00:00 +0000 2012   \n",
       "4  4           Mon Oct 22 05:00:00 +0000 2012   \n",
       "\n",
       "                                                                                                   text  \\\n",
       "0  I suppose she has an appropriate costume for every activity... #ilovemaggiesmith #downtonseasonthree   \n",
       "1  @NOT_savinHOES Not r yu upp                                                                            \n",
       "2  Hit and Run is so sad..                                                                                \n",
       "3  Who's up?                                                                                              \n",
       "4  @augustushazel idk I'm just ugly or annoying or something                                              \n",
       "\n",
       "   retweet_count lang                   place_name coordinates_longitude  \\\n",
       "0  0              en   West Long Branch, NJ         -74.037008             \n",
       "1  0              en   Bressler-Enhaut-Oberlin, PA  -76.831479             \n",
       "2  0              en   South Carolina, USA          -83.353955             \n",
       "3  0              en   Malden, MA                   -71.089522             \n",
       "4  0              en   Erie, PA                     -80.239991             \n",
       "\n",
       "  coordinates_latitude  \n",
       "0  40.272289            \n",
       "1  40.22417             \n",
       "2  32.04683             \n",
       "3  42.412466            \n",
       "4  42.018414            "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_test['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>place_name</th>\n",
       "      <th>coordinates_longitude</th>\n",
       "      <th>coordinates_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>I suppose she has an appropriate costume for every activity... #ilovemaggiesmith #downtonseasonthree</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>West Long Branch, NJ</td>\n",
       "      <td>-74.037008</td>\n",
       "      <td>40.272289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>@NOT_savinHOES Not r yu upp</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Bressler-Enhaut-Oberlin, PA</td>\n",
       "      <td>-76.831479</td>\n",
       "      <td>40.22417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>Hit and Run is so sad..</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>South Carolina, USA</td>\n",
       "      <td>-83.353955</td>\n",
       "      <td>32.04683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>Who's up?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Malden, MA</td>\n",
       "      <td>-71.089522</td>\n",
       "      <td>42.412466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Oct 22 05:00:00 +0000 2012</td>\n",
       "      <td>@augustushazel idk I'm just ugly or annoying or something</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Erie, PA</td>\n",
       "      <td>-80.239991</td>\n",
       "      <td>42.018414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Mon Oct 22 05:00:00 +0000 2012   \n",
       "1  Mon Oct 22 05:00:00 +0000 2012   \n",
       "2  Mon Oct 22 05:00:00 +0000 2012   \n",
       "3  Mon Oct 22 05:00:00 +0000 2012   \n",
       "4  Mon Oct 22 05:00:00 +0000 2012   \n",
       "\n",
       "                                                                                                   text  \\\n",
       "0  I suppose she has an appropriate costume for every activity... #ilovemaggiesmith #downtonseasonthree   \n",
       "1  @NOT_savinHOES Not r yu upp                                                                            \n",
       "2  Hit and Run is so sad..                                                                                \n",
       "3  Who's up?                                                                                              \n",
       "4  @augustushazel idk I'm just ugly or annoying or something                                              \n",
       "\n",
       "   retweet_count lang                   place_name coordinates_longitude  \\\n",
       "0  0              en   West Long Branch, NJ         -74.037008             \n",
       "1  0              en   Bressler-Enhaut-Oberlin, PA  -76.831479             \n",
       "2  0              en   South Carolina, USA          -83.353955             \n",
       "3  0              en   Malden, MA                   -71.089522             \n",
       "4  0              en   Erie, PA                     -80.239991             \n",
       "\n",
       "  coordinates_latitude  \n",
       "0  40.272289            \n",
       "1  40.22417             \n",
       "2  32.04683             \n",
       "3  42.412466            \n",
       "4  42.018414            "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = dataset_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gs_lr_tf.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = pd.DataFrame({'Tweet': dataset_test['text'], 'Prediction' : preds , \n",
    "                          'longitude':dataset_test['coordinates_longitude'],\n",
    "                         'latitude':dataset_test['coordinates_latitude']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I suppose she has an appropriate costume for every activity... #ilovemaggiesmith #downtonseasonthree</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.037008</td>\n",
       "      <td>40.272289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@NOT_savinHOES Not r yu upp</td>\n",
       "      <td>0</td>\n",
       "      <td>-76.831479</td>\n",
       "      <td>40.22417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hit and Run is so sad..</td>\n",
       "      <td>0</td>\n",
       "      <td>-83.353955</td>\n",
       "      <td>32.04683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who's up?</td>\n",
       "      <td>0</td>\n",
       "      <td>-71.089522</td>\n",
       "      <td>42.412466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@augustushazel idk I'm just ugly or annoying or something</td>\n",
       "      <td>0</td>\n",
       "      <td>-80.239991</td>\n",
       "      <td>42.018414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  Tweet  \\\n",
       "0  I suppose she has an appropriate costume for every activity... #ilovemaggiesmith #downtonseasonthree   \n",
       "1  @NOT_savinHOES Not r yu upp                                                                            \n",
       "2  Hit and Run is so sad..                                                                                \n",
       "3  Who's up?                                                                                              \n",
       "4  @augustushazel idk I'm just ugly or annoying or something                                              \n",
       "\n",
       "   Prediction   longitude   latitude  \n",
       "0  0           -74.037008  40.272289  \n",
       "1  0           -76.831479  40.22417   \n",
       "2  0           -83.353955  32.04683   \n",
       "3  0           -71.089522  42.412466  \n",
       "4  0           -80.239991  42.018414  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102254, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    101727\n",
       "1    527   \n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_preds['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 102254 tweets that was collected from all over the united states during the time of hurrican sandy, our model predicted that 527 were disaster realted tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_preds = pd.DataFrame(new_preds[new_preds['Prediction'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_preds.to_csv('final_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took our final 527 prediction tweets csv file with its geo location and ploted on the map using tableau public. As you can see most the tweets are coming from states like New york, New jersery, virgnia, basically all the sates along the coast that were impacted the most. Since our model is not 100 percent accurate, we do have noise coming from different states. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](prediction_location.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
